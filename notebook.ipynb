{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installing dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    gemini_env = \"GEMINI_API_KEY\"\n",
    "    model_clip = \"ViT-B/32\"\n",
    "    model_gemini = \"gemini-1.5-flash\"\n",
    "    model_embedding = \"models/embedding-001\"\n",
    "    model_embedding_text = \"models/embedding-001\"\n",
    "    database_path = \"./database\"\n",
    "    database_image = \"images\"\n",
    "    database_text = \"text\"\n",
    "    database_table = \"table\"\n",
    "    document_path = \"./assets/AnatomyAndPhysiology-LR.pdf\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import dotenv\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import clip\n",
    "import chromadb\n",
    "import google.generativeai as genai\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_api_key = os.getenv(Config.gemini_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(Config.document_path,extract_images=False)\n",
    "pdf = loader.load()\n",
    "documents = pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = chromadb.PersistentClient(path=Config.database_path)\n",
    "text_db = client.get_or_create_collection(Config.database_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_db = client.get_or_create_collection(Config.database_image)\n",
    "clip_model, preprocess = clip.load(Config.model_clip, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_image(image_path):\n",
    "    image = preprocess(Image.open(image_path)).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        image_embedding = clip_model.encode_image(image).cpu().numpy()\n",
    "    return image_embedding\n",
    "def encode_text(text):\n",
    "    text = clip.tokenize([text],truncate=True).to(device)\n",
    "    with torch.no_grad():\n",
    "        text_embedding = clip_model.encode_text(text).cpu().numpy()\n",
    "    return text_embedding\n",
    "def add_image(image_path):\n",
    "    image_emb = encode_image(image_path)\n",
    "    image_db.add(embeddings=image_emb.tolist(), metadatas=[{\"image_path\": image_path}], ids=[image_path])\n",
    "def search_image(caption,n_results=2):\n",
    "    text_embedding = encode_text(caption)\n",
    "    results = image_db.query(query_embeddings=text_embedding.tolist(), n_results=n_results)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading text into Vector DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_text(text:str,api_key_number:int):\n",
    "    api_key = os.getenv(f\"GEMINI_API_KEY{api_key_number}\")\n",
    "    if api_key is None:\n",
    "        raise ValueError(f\"GEMINI_API_KEY{api_key_number} not found\")\n",
    "    genai.configure(api_key=api_key)\n",
    "    model=Config.model_embedding\n",
    "    return genai.embed_content(\n",
    "        model=model,\n",
    "        content=text,\n",
    "        task_type=\"retrieval_document\",\n",
    "    )['embedding']\n",
    "\n",
    "def load_and_process_pdf(pdf_path, text_db):\n",
    "    # Load the PDF\n",
    "    global documents  # Declare documents as a global variable\n",
    "    if 'documents' not in globals():\n",
    "        print(\"Loading pdf\")\n",
    "        loader = PyPDFLoader(pdf_path)\n",
    "        documents = loader.load()\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=512, chunk_overlap=100)\n",
    "\n",
    "    # Embed and store each page as a chunk\n",
    "    for doc in tqdm(documents[16:17], desc=\"Processing pages\"):\n",
    "        chunks = text_splitter.split_text(doc.page_content)\n",
    "        for i, chunk in enumerate(chunks):\n",
    "            chunk_embedding = embed_text(chunk, api_key_number=1)\n",
    "            text_db.add(embeddings=chunk_embedding, ids=[str(doc.metadata['page']) + '*' + str(i)])\n",
    "\n",
    "load_and_process_pdf(Config.document_path, text_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_page_range(pages):\n",
    "    # Create a set of unique pages and expand the range by including adjacent pages\n",
    "    unique_pages = set(pages)\n",
    "    for page in pages:\n",
    "        if page - 1 >= 0:\n",
    "            unique_pages.add(page - 1)  # Add previous page if it exists\n",
    "        unique_pages.add(page + 1)      # Always add the next page\n",
    "    return list(sorted(unique_pages))\n",
    "\n",
    "def retrieve_pages(text_db, query, top_k:int=3, expand_pages:bool=False):\n",
    "    # Embed the query and retrieve the top K pages from the text database\n",
    "    text_embedding = embed_text(query)\n",
    "    results = text_db.query(query_embeddings=text_embedding, n_results=top_k)['ids'][0]\n",
    "    pages = [int(page) for page in results]\n",
    "    if expand_pages:\n",
    "        pages = expand_page_range(pages)  # Expand page range if requested\n",
    "    return pages\n",
    "\n",
    "def prompt_fromatting(prompt: str, document: str):\n",
    "    # Format the prompt for the AI model with specific instructions\n",
    "    prompt = (\n",
    "        \"You are AI designed to provide accurate and concise answers to your questions about the human body's anatomy.\\n\"\n",
    "        \"Retrieves information from a vast repository of provided anatomical content to respond to questions.\\n\"\n",
    "        \"Respond with a clear and accurate answer based on the provided content from the document.\\n\"\n",
    "        \"If the question is unclear or requires additional context, this application will ask for clarification before providing an answer.\\n\"\n",
    "        \"If the question requests an explanation in detail, please provide an elaborate response based on the information given in the document.\\n\"\n",
    "        f\"Question: {prompt}\\n\"\n",
    "        f\"Document: {document}\\n\"\n",
    "        \"Note: Responses are limited to the provided anatomical content and do not include personal opinions or external consultations.\"\n",
    "    )\n",
    "    return prompt\n",
    "\n",
    "def prepare_prompt(query, expand_pages=False):\n",
    "    # Prepare the prompt by retrieving relevant pages and formatting the content\n",
    "    pages = retrieve_pages(text_db, query, expand_pages=expand_pages)\n",
    "    page_content = ''\n",
    "    for page in pages:\n",
    "        page_content += pdf[page].page_content + '\\n'  # Concatenate content from each page\n",
    "    return prompt_fromatting(query, page_content), pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'explain metabolism in detail'\n",
    "prompt,pages = prepare_prompt(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key=gemini_api_key)\n",
    "model = genai.GenerativeModel(Config.model_gemini)\n",
    "response = model.generate_content(\n",
    "    prompt,\n",
    "    generation_config = genai.GenerationConfig(\n",
    "        max_output_tokens=1000,\n",
    "        temperature=0.1,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metabolism is the sum of all chemical reactions that occur in the body. It encompasses both anabolism and catabolism. \n",
      "\n",
      "* **Anabolism** is the process of building larger, more complex molecules from smaller, simpler ones. This process requires energy. For example, your body uses energy to assemble complex chemicals from small molecules derived from the food you eat.\n",
      "* **Catabolism** is the process of breaking down larger, more complex molecules into smaller, simpler ones. This process releases energy. For example, the complex molecules found in food are broken down so the body can use their parts to assemble the structures and substances needed for life.\n",
      "\n",
      "Both anabolism and catabolism occur simultaneously and continuously to keep you alive. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(response.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
